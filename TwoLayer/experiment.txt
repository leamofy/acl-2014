For experiment, the threshold of page rank is set to 0.01;

Reference BLEU: for every reference sentence, compute the bleu score against other three references. Then the bleu score of
references is the average of the bleu scores of four referances.

Oracle(Seg) trans:for every translation, compute the average TER  against 4 references,select the translation with the lowest averaged TER.

Oracle(Seg) trans and edits: for every translation or edition, compute the average TER  against 4 references,select the translation or edition with the lowest average TER.

Oracle(MTurker) trans:For every translation, get the averaged TER score of its translator. Select the translation generated by the translator with the highest averaged TER 

Oracle(MTurker) trans and edits:for every translation, get the averaged TER score of its translator, use it as its TER score;for every edition, get the averaged TER improved 
score of its editor and the averaged TER score of its editor's co-working translator, and use the difference of the two values as the edition's TER score. 
Finally, select the translation or edition with the lowest TER score.

Lowest TER:for every translation, compute the average TER against other 3 translation,select the translation with the lowest average TER.

Raw Translation:For every translation, compute the average cosine similarity against other 3 translation, select the translation with the highest average cosine similarity.

Single Layer(Sentence Layer) Page Rank: implement page rank on single-layer sentences graph.

Two Layer Page Rank:Two Layer (MTurkers layer and Sentences layer)Page Rank 

Random Base Line(PBaseLine.java,Main.java): randomly select one translation from four translations.
 